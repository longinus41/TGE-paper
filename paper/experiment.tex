% !TEX root = main.tex

\section{Experiments}
In this section, we conduct experiments to evaluate the performance of our method via node classification on ETG.

\subsection{Data Collection and Graph Construction}
We collect all data by running Ethereum client\footnote{Parity Ethereum Client, https://www.parity.io/ethereum/} which maintains the same copy of blockchain with all historical transactions. Note that we choose the transaction logs on Ethereum from January 1, 2018 to March 31, 2018 (116,293,867 external transactions and internal transactions in total) as the input of graph construction since it is the most active period with various activities.

By parsing the transactions, 16,599,825 active accounts are obtained, including 14,450,993 EOAs and 2,148,831 SCs. Then we construct the original ETG based on these accounts and transactions.

Specially, we extend the pre-processing scheme to adapt our model. First we construct four relation graphs, which contains ETH transfer graph, contract creation graph, contract invocation graph and mining reward graph. In each graph, repeated edges between the same node pair are merged via the method introduced in section \ref{section:time}.

Last, a test set of accounts with label introduced before is provided to evaluate classification accuracy. It is hard to reveal the identity of addresses since the anonymity of blockchain. We obtain these labeled examples in two ways, \emph{Etherscan}\footnote{Etherscan LabelCloud, https://etherscan.io/labelcloud} and \emph{Searchain}\footnote{Searchain, http://www.searchain.io/}. In the label set, the number of samples of each category is 100.

\subsection{Experimental Set-Up and Baselines}
As a baseline for our experiments, we compare against state-of-the-art classification results from \textcolor{red}{DeepWalk~\cite{perozzi2014deepwalk}, PARW~\cite{wu2012learning}, rGCN~\cite{schlichtkrull2018modeling} and ...}. DeepWalk uses random walks on graphs to obtain node representations. Due to DeepWalk is unsupervised method, a logistic regression model is added for classification. As a label propagation method, PARW is guaranteed to implement the cluster assumption in the sense that under proper absorption rates. rGCN is a kind of deep neural network based methods and can be applied to modeling relational data. 

Unless otherwise noted, all the GCN-based hidden layer has 16 units. Models are trained with Adam optimizer for 100 epochs, and dropout with $dropout\_rate=0.5$ is utilized to avoid overfitting.

\begin{table*}
\footnotesize
\centering
\caption{}
\resizebox{\textwidth}{17mm}{
\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc}
\toprule
 & \multicolumn{3}{c|}{Deepwalk} & \multicolumn{3}{c|}{PARW} & \multicolumn{3}{c|}{rGCN} & \multicolumn{3}{c|}{rGCN+asymmetric proximity} & \multicolumn{3}{c}{Ours} \\
\midrule
& \textbf{Precision} & \textbf{Recall} & $\mathbf{F_1}$ & \textbf{Precision} & \textbf{Recall} & $\mathbf{F_1}$ & \textbf{Precision} & \textbf{Recall} & $\mathbf{F_1}$ & \textbf{Precision} & \textbf{Recall} & $\mathbf{F_1}$ & \textbf{Precision} & \textbf{Recall} & $\mathbf{F_1}$ \\
\midrule
 phish and hack & 0.609 & 0.394 & 0.479 &0.565 & 0.333 & 0.419 & 0.913& 0.212& 0.344& 0.720& 0.727& 0.724& 0.714& 0.758& 0.735\\
 token contract & 0.857& 0.735 & 0.791 &0.354& 0.718& 0.475& 0.908& 0.602& 0.724& 0.958& 0.939& 0.949& 0.958& 0.939& 0.949\\
 exchange deposit & 0.586 & 0.531 & 0.557 &0.692& 0.281& 0.400& 0.688& 0.440& 0.537& 0.615& 0.640& 0.628& 0.556& 0.600& 0.579\\
 exchange root & 0.647 & 0.759 & 0.698 &0.667& 0.759& 0.710& 0.923& 0.686& 0.787& 0.862& 0.714& 0.781& 0.828& 0.686& 0.750\\
 pool & 0.692 & 0.750 & 0.720 &0.789& 0.625& 0.697& 1.000& 0.727& 0.842& 0.842& 0.727& 0.781& 1.000& 0.727& 0.842\\
 miner & 0.400 & 0.694 & 0.508 &0.667& 0.872& 0.756& 0.867& 0.951& 0.907& 0.826& 0.927& 0.874& 0.841& 0.902& 0.871\\
 primary market & 0.405 & 0.548 & 0.466 & 0.727& 0.516& 0.604& 0.739& 0.548& 0.630& 0.680& 0.548& 0.607& 0.750& 0.484& 0.588\\
 ICO wallet & 0.364 & 0.353 & 0.358 & 0.630& 0.500& 0.558& 0.546& 0.158& 0.245& 0.769& 0.526& 0.625& 0.742& 0.605& 0.668\\
 \midrule
 average & 0.614 & 0.583 & \bf{0.585} & 0.623& 0.577& \bf{0.570}& 0.848& 0.496& \bf{0.593}& 0.806& 0.761& \bf{0.779}& 0.811& 0.764& \bf{0.782}\\
\bottomrule
\end{tabular}
}
\end{table*}

All embedding and classification programs were run on the server, which includes Intel Xeon E5 CPU with 55 processors and 128GB of memory, and the GPU used for deep learning is Nvidia 1080.

\subsection{Classification Results}
In the first experiment, we test XXX on classification with the label set. 

We use three indicators to evaluate each model, including precision, recall and $F_1$ score. Precision is the fraction of relevant instances among the retrieved instances, while recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. And $F_1$ score is a measure that combines precision and recall, which is computed as
\begin{equation}
F_1=(\frac{{precision}^{-1}+{recall}^{-1}}{2})^{-1}=2\cdot\frac{precision \cdot recall}{precision + recall}
\end{equation}

In statistical analysis of multi-label classification, the $F_1$ score is an important indicator since it is the harmonic average of the precision and recall.

\subsection{Asymmetric Proximity and Time-Density}

%These data are collected

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "analysis"
%%% End:
